{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7590738,"sourceType":"datasetVersion","datasetId":4418374}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-26T11:26:06.073017Z","iopub.execute_input":"2024-09-26T11:26:06.073430Z","iopub.status.idle":"2024-09-26T11:26:06.517753Z","shell.execute_reply.started":"2024-09-26T11:26:06.073389Z","shell.execute_reply":"2024-09-26T11:26:06.516653Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/job_summary.csv\n/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/job_skills.csv\n/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/linkedin_job_postings.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = pd.read_csv('/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/job_summary.csv')\nskills = pd.read_csv('/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/job_skills.csv')\npostings = pd.read_csv('/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/linkedin_job_postings.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-26T11:26:06.519500Z","iopub.execute_input":"2024-09-26T11:26:06.519944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df = pd.merge(summary,skills,on='job_link',how='outer')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(merged_df, postings, on='job_link', how='outer')\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(subset=['company','job_location'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_short = df[df['job_summary'].isnull() & df['job_skills'].isnull()]\ndf_short.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_short.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new = df.drop(['job_summary','job_skills','job_link','search_city','last_processed_time','got_summary','got_ner','is_being_worked'],axis=1)\ndf_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_try = df_new.rename(columns={'job_title': 'title', \n                            'job_location': 'location', \n                            'search_country': 'country'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new = df_new.drop(['search_country'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_one = pd.DataFrame()\ndf_one['tags'] = df_new['job_title'] + ' ' + \\\n                              df_new['company'] + ' ' + \\\n                              df_new['job_location'] + ' ' + \\\n                              df_new['search_position'] + ' ' + \\\n                              df_new['job_level'] + ' ' + \\\n                              df_new['job_type']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_one.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_duplicate_words(tag_list):\n    cleaned_tags = []\n    for tags in tag_list:\n        words = tags.split()\n        unique_words = list(dict.fromkeys(words))  \n        cleaned_tags.append(' '.join(unique_words))\n    return cleaned_tags\n\n# Apply the function only to the 'tags' column\ndf_one['new_tags'] = remove_duplicate_words(df_one['tags'])\n\n# Drop the original 'tags' column\ndf_two = df_one.drop(['tags'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_two['new_tags'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_one['tags'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndf_two['new_tags'] = df_two['new_tags'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfid = TfidfVectorizer(stop_words='english')\n\ntfid_matrix = tfid.fit_transform(df_two['new_tags'])\nprint(tfid_matrix.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_input = \"Database Manager in India\"\n\ninput_tfid = tfid.transform([user_input])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim = cosine_similarity(input_tfid, tfid_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cosine_sim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sim_scores = cosine_sim[0]\njob_indices = sim_scores.argsort()[::-1]\ntop_n = 15\ntop_job_indices = job_indices[:top_n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommended_jobs = df_two.iloc[top_job_indices]\nrecommended_jobs.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"job_ids = recommended_jobs.index\njob_ids_list = job_ids.tolist()\njob_ids_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in job_ids_list:\n    print(df['job_link'][i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2 = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2['job_summary'].fillna('None',inplace=True)\ndf_2['job_skills'].fillna('None',inplace=True)\ndf_2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_skill = pd.DataFrame\ndf_skill = df_2[['job_skills','job_title']]\ndf_skill.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom collections import Counter\n\n\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(df_skill['job_title'])\n\nnum_clusters = 15\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\ndf_skill['cluster'] = kmeans.fit_predict(X)\n\ndef get_top_skills(cluster_num, n_top_skills=5):\n    skills_in_cluster = df_skill[df_skill['cluster'] == cluster_num]['job_skills']\n    all_skills = ', '.join(skills_in_cluster)\n    skill_list = all_skills.split(', ')\n    most_common_skills = Counter(skill_list).most_common(n_top_skills)\n    return [skill for skill, freq in most_common_skills]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"job_title = \"Software Developer\"\ncluster = kmeans.predict(vectorizer.transform([job_title]))[0]\ntop_skills = get_top_skills(cluster)\n\nprint(f\"Top skills for '{job_title}': {top_skills}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"technical_skills = ['JavaScript', 'Python', 'C', 'C++', 'Java', 'SQL', 'HTML', 'CSS', 'React', 'Node.js']\n\ndef extract_technical_skills(skills):\n    return [skill for skill in skills.split(', ') if skill in technical_skills]\n\ndf_skill['technical_skills'] = df_skill['job_skills'].apply(extract_technical_skills)\n\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(df_skill['job_title'])\n\nnum_clusters = 10\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\ndf_skill['cluster'] = kmeans.fit_predict(X)\n\ndef get_top_skills(cluster_num, n_top_skills=5):\n    skills_in_cluster = df_skill[df_skill['cluster'] == cluster_num]['technical_skills']\n    all_skills = [skill for sublist in skills_in_cluster for skill in sublist]\n    most_common_skills = Counter(all_skills).most_common(n_top_skills)\n    return [skill for skill, freq in most_common_skills]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"job_title = \"Web Developer\"\ncluster = kmeans.predict(vectorizer.transform([job_title]))[0]\ntop_skills = get_top_skills(cluster)\n\nprint(f\"Top skills for '{job_title}': {top_skills}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"technical_skills = ['JavaScript', 'Python', 'C', 'C++', 'Java', 'SQL', 'HTML', 'CSS', 'React', 'Node.js']\n\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(df_skill['job_title'])\n\nnum_clusters = 10\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\ndf_skill['cluster'] = kmeans.fit_predict(X)\n\ndef get_top_skills(cluster_num, n_top_skills=5):\n    skills_in_cluster = df_skill[df_skill['cluster'] == cluster_num]['job_skills']\n    all_skills = ', '.join(skills_in_cluster).split(', ')\n    \n    # Count all skills and technical skills separately\n    all_skills_count = Counter(all_skills)\n    tech_skills_count = Counter([skill for skill in all_skills if skill in technical_skills])\n\n    # Combine results, favoring technical skills\n    combined_count = {}\n    for skill in all_skills_count:\n        combined_count[skill] = all_skills_count[skill] + (tech_skills_count[skill] * 2)  # Weight technical skills more\n\n    # Get the most common skills based on combined scoring\n    most_common_skills = Counter(combined_count).most_common(n_top_skills)\n    return [skill for skill, _ in most_common_skills]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"job_title = \"Database Manager\"\ncluster = kmeans.predict(vectorizer.transform([job_title]))[0]\ntop_skills = get_top_skills(cluster)\n\nprint(f\"Top skills for '{job_title}': {top_skills}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}